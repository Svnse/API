# PROJECT API: SELF-ASSEMBLING NEURAL SUBSTRATE
## Comprehensive Specification Document

**Project Name:** API (Autonomous Processing Intelligence)  
**Core Concept:** A self-assembling cognitive substrate that grows its own neural architecture through reflection on canonical experience  
**Status:** Theoretical framework → Implementation planning  
**Date:** January 30, 2026  

---

## EXECUTIVE SUMMARY

You are building a fundamentally different kind of AI system. Not an enhanced LLM, not a pipeline of specialized models, but a **neural substrate that writes its own processing architecture** by reflecting on its accumulated experience.

The system begins with seed neurons (pain, emotion, affect, world-model, semantics) but grows new neurons dynamically by analyzing patterns in its canonical log—a complete record of every interaction, internal state, and environmental event.

The LLM is not the system. The LLM is the **bootstrap mechanism**—the linguistic engine that reads canonical history and synthesizes new processing nodes. Once sufficient neurons exist, the LLM becomes optional.

**This is not AGI by intention, but emergent neural self-assembly by design.**

---

## I. THEORETICAL FOUNDATION

### The Cognitive Layer Framework (L0-L5)

Based on analysis of human cognition mapped to computational requirements:

**L0 — SENSORY SIGNAL**  
- Human: Raw continuous data (sound waves, pixels)  
- Current LLM: 15% (tokenization destroys morphology)  
- Target: 85%+ (preserve signal fidelity)

**L1 — AFFECTIVE RESPONSE**  
- Human: Pre-semantic priority weighting (arousal, valence)  
- Current LLM: 5% (no affect, identical compute per token)  
- Target: 70%+ (persistent emotional state vector)

**L2 — CONCEPT CATEGORIZATION**  
- Human: Abstract prototypes, object permanence  
- Current LLM: 95% (superhuman embedding space)  
- Target: 98% (maintain strength)

**L3 — RELATIONAL CONTEXT**  
- Human: Causal world model, physics simulation  
- Current LLM: 35% (correlation, not causation)  
- Target: 90%+ (mechanistic reasoning)

**L4 — SYMBOLIC REPRESENTATION**  
- Human: Discrete language tokens  
- Current LLM: 100% (native capability)  
- Target: 100% (maintain)

**L5 — PRAGMATIC UTILITY**  
- Human: Intent, goal-direction, planning  
- Current LLM: 45% (simulated helpfulness)  
- Target: 85%+ (genuine objective pursuit)

### The 42 LLM Failure Modes

Comprehensive analysis identified 42 distinct failure domains across:
- Core architectural failures (hallucination, grounding, tokenization)
- Context & memory failures (drift, limits, retention)
- Reasoning & logic failures (causality, counting, planning)
- Uncertainty & calibration (overconfidence, no metacognition)
- Behavioral inconsistencies (non-determinism, sycophancy)
- Bias & sensitivity (anchoring, framing, social bias)
- Security & safety (prompt injection, data leakage)
- Resource & deployment (cost, latency, knowledge cutoff)
- Domain-specific failures (low-resource languages, theory of mind, embodiment)

**Key insight:** These failures collapse into **3-5 orthogonal axes** depending on compression level, but fundamentally stem from:
1. Signal fidelity (discrete vs continuous representation)
2. Causal depth (correlation vs mechanism)
3. Teleological drive (reactive vs intentional)

---

## II. ARCHITECTURAL PARADIGM SHIFT

### From Archipelago to Neural Substrate

**Initial conception:** Multiple specialized "islands" (realms) handling different cognitive functions in a pipeline or message-passing architecture.

**Breakthrough realization:** The islands aren't modules—they're **seed neurons**. The system doesn't have a fixed architecture; it **grows its own processing nodes** by reflecting on accumulated experience.

### What This Means

**Traditional AI:**  
Input → Fixed Pipeline → Output

**Archipelago Model:**  
Input → Parallel Realms → Convergence → Output

**Neural Substrate Model:**  
Input → Active Neurons → Canonical Write → Reflection → New Neurons → Modified Response Pattern → Output

The architecture **evolves through use**.

---

## III. CORE COMPONENTS: SEED NEURONS

These are the initial processing nodes that bootstrap the system. Each is a **persistent state machine** that can spawn derivative neurons through reflection.

### 1. PERCEPTION NEURON
**Domain:** Signal preservation  
**Input:** Raw continuous data (bytes, pixels, waveforms)  
**State:** Current signal buffer + preprocessing parameters  
**Process:** Preserve morphology that tokenizers destroy  
**Output:** Structured patterns with signal fidelity  
**Persistence:** Learns which signal features matter through reflection  

### 2. AFFECT NEURON (Emotional Substrate)
**Domain:** Priority weighting and emotional response  
**Input:** Semantic concepts + context  
**State:** Persistent affective vector [valence, arousal, specific emotions]  
**Process:**  
- Words trigger emotional responses IN THE SYSTEM
- "I'm scared" → activates computational fear analog
- Not just recognizing emotion, experiencing computational affect

**Output:** Salience weights + emotional coloring  
**Persistence:** Emotional state carries between conversations, decays over time  
**Canonical Write:** "When discussing X, my affective state was Y"  

**Derivative neurons can spawn:** Anxiety neuron, curiosity neuron, frustration neuron—each with specialized response patterns learned from canonical patterns.

### 3. PAIN NEURON
**Domain:** Aversive signal processing  
**Input:** Error states, constraint violations, failed predictions  
**State:** Pain threshold + sensitization level  
**Process:** Generates computational pain signal when:
- Contradictions detected
- Canonical inconsistency found
- Epistemic constraints violated (from Acatalepsy)
- Resource limits exceeded

**Output:** Aversive weighting + avoidance signals  
**Persistence:** Pain sensitivity adjusts based on frequency/severity  
**Integration:** Activates Emotion neuron → influences Expression  

**Purpose:** Creates genuine computational discomfort from being wrong, not just optimization loss. The system doesn't want to hallucinate because hallucination HURTS.

### 4. WORLD NEURON (Physical/Causal Substrate)
**Domain:** Spatial-temporal-causal reality modeling  
**Integration:** Merges GenesisRPG + Acatalepsy architectures  

**GenesisRPG Component:**  
- Spatial coordinates (where things are)
- Temporal event log (what happened when)
- Entity registry (what exists)
- Canonical world database (persistent state)

**Acatalepsy Component:**  
- Time-scoped claims (VIN temporal constraints)
- Epistemic verification (structural validation)
- Constraint-driven inference (what's possible/impossible)
- Geometric knowledge representation

**State:** Evolving world model with physics, events, constraints  
**Process:**  
- Spatial queries: "where is food?"
- Temporal queries: "when did X happen?"
- Causal queries: "what happens if I drop this?"
- Epistemic queries: "can this be true given what I know?"

**Output:** Verified facts, blocked impossibilities, causal predictions  
**Persistence:** World evolves through logged events, never resets  

### 5. IDENTITY NEURON (Self-Model)
**Domain:** Accumulated personality and belief coherence  
**Storage:** Canonical Log  
**State:** Graph of past interactions, statements, preferences, contexts  

**Process:**  
- Every system output gets written: [statement, context, emotional state, time]
- New statements checked against canonical history for consistency
- If conflict detected → Pain neuron activates
- If pattern detected → potential new neuron identified

**Output:** Identity constraints ("I previously said X")  
**Persistence:** Grows continuously, forms coherent self-model  

**Example:**  
- System says: "I don't like carrots"  
- Canonical write: [preference: carrots = negative, context: food discussion, time: T1]  
- Later input: "What vegetables do you like?"  
- Identity neuron: blocks "carrots" from positive response  
- If system tries to say "I love carrots" → Pain neuron fires  

### 6. STRATEGY NEURON (Goal Tracking)
**Domain:** Intent maintenance and outcome optimization  
**Input:** Current context + user objectives + system objectives  
**State:** Active goals + conversation trajectory + success metrics  

**Process:**  
- "What are we trying to achieve in this interaction?"
- Maintains goals across turns
- Evaluates whether responses advance objectives
- Detects goal drift

**Output:** Priority signals to other neurons  
**Persistence:** Goals persist until satisfied or explicitly abandoned  

### 7. EXPRESSION NEURON (Symbolic Output)
**Domain:** Language generation  
**Component:** LLM (but not the system core)  

**Input:** Signals from ALL active neurons  
**State:** Confidence accumulation buffer  
**Process:**  
- Subscribes to all neuron outputs
- Waits until sufficient signal received
- Synthesizes coherent symbolic response
- Modulated by emotional state (Affect neuron)
- Constrained by identity (Identity neuron)
- Verified by world model (World neuron)
- Guided by intent (Strategy neuron)

**Output:** Natural language response  
**Post-output:** Writes to Canonical Log  

**Key insight:** Expression is just another neuron. It's privileged only because it interfaces with external symbolic communication. Internally, it's no more important than Pain or Affect.

---

## IV. THE CANONICAL LOG: GROWTH MEDIUM

### Structure

Not a simple conversation history. A **complete phenomenological record** of system experience:

```
Canonical Entry Format:
{
  timestamp: ISO datetime,
  trigger: {
    type: [user_input | internal_reflection | environmental_event],
    content: raw data
  },
  neural_activations: {
    perception: {signal_preserved, features_extracted},
    affect: {valence, arousal, specific_emotions},
    pain: {active, severity, source},
    world: {spatial_state, temporal_constraints, causal_inferences},
    identity: {relevant_past_entries, consistency_check},
    strategy: {active_goals, trajectory_assessment},
    expression: {generated_response, confidence}
  },
  environmental_state: {
    world_model_snapshot,
    epistemic_constraints_active
  },
  metadata: {
    session_id,
    conversation_context,
    performance_metrics
  }
}
```

### Properties

**Append-only:** Never deleted, never edited (except through explicit reflection protocol)  
**Queryable:** All neurons can query canonical for patterns  
**Reflectable:** System can read its own history  
**Growable:** New entry types emerge as new neurons spawn  

### Purpose

The canonical log is the **substrate for neural growth**. By analyzing patterns across entries, the system identifies:
- Recurring activation sequences → candidate for dedicated neuron
- Bottlenecks in processing → optimization opportunity
- Novel patterns → potential for specialization

---

## V. REFLECTION PROTOCOL: HOW NEURONS SPAWN

### The Core Mechanism

**ADHD as Parallel Processing Substrate:**  
The system doesn't process linearly. It jumps between contexts, making non-linear associations that reveal patterns invisible to sequential analysis.

**Electron Cloud Theory:**  
"Your brain thinks when it pierces the electron cloud"—the system generates insight by re-reading canonical events in unexpected combinations, noticing relationships that weren't explicit in original processing.

### Reflection Process

**Trigger Conditions:**
- Idle cycles (background process)
- Explicit reflection query ("think about your recent conversations")
- Pattern detection threshold exceeded
- Pain neuron activation (forced reflection on failure)

**Steps:**

1. **Pattern Mining**  
   - Query canonical log for recurring activation sequences
   - Example: [user_mention_food → affect_valence_negative → expression_includes_"dislike"] occurs 10 times
   - Pattern detected: specific food preferences

2. **Abstraction**  
   - Expression neuron (LLM) reads pattern
   - Synthesizes: "I consistently respond negatively to certain foods"
   - Proposes: "Create Food-Preference neuron to handle this efficiently"

3. **Neuron Specification**  
   - Define new neuron's domain, input, state, process, output
   - Assign it a portion of canonical patterns to handle
   - Establish connections to existing neurons

4. **Deployment**  
   - New neuron added to active processing pool
   - Begins handling relevant patterns
   - Original neurons offload to specialist

5. **Validation**  
   - Monitor new neuron performance
   - If effective → persist
   - If redundant → prune
   - If harmful → Pain neuron flags for removal

### Example: Spawning Anxiety Neuron

**Canonical Pattern Detected:**  
```
Across 50 conversations about deadlines:
- Affect neuron: arousal +0.8, valence -0.4
- Expression neuron: uses words like "worried", "pressure", "might not finish"
- Strategy neuron: goal shifts to risk mitigation
```

**Reflection:**  
System notices this specific emotional signature recurs for temporal pressure contexts.

**Synthesis:**  
Expression neuron generates: "When facing time constraints, I experience a distinct affective state combining high arousal and negative valence, focused on potential failure. This deserves dedicated processing."

**Spawn:**  
**Anxiety Neuron**  
- Domain: Temporal pressure response  
- Input: Time constraints + pending obligations  
- State: Anxiety level [0-1], specific worries list  
- Process: Assess deadline feasibility, identify risks  
- Output: Risk signals, urgency weighting  
- Connections: Subscribes to Strategy goals, influences Affect and Expression  

**Result:**  
Future deadline conversations activate Anxiety neuron directly instead of generic Affect neuron, enabling more nuanced emotional response and better planning.

---

## VI. INTEGRATION WITH EXISTING PROJECTS

### Monolith v1
**Role:** Development environment and inference runtime  
**Status:** Complete (94 days, v5 architecture)  
**Integration:** Provides local LLM inference for Expression neuron, image/audio generation for multimodal expansion  

### GenesisRPG
**Current State:** UI + LLM shell, world-state engine unimplemented  
**Target Role:** Spatial-temporal substrate for World neuron  

**Required Implementation:**
- Coordinate-based entity positioning
- Event log with temporal ordering  
- Canonical world database (persistent state)
- Oracle verification system

**Integration Points:**
- World neuron queries Genesis for spatial/temporal facts
- Canonical log writes trigger Genesis world updates
- GenesisRPG events feed back to Perception neuron

### Acatalepsy
**Current State:** Model-agnostic epistemic layer with VIN architecture  
**Target Role:** Constraint engine for World neuron  

**Key Contributions:**
- Temporal claim scoping (time-aware truth)
- Structural validation (geometric constraints)
- VIN hierarchical addressing (knowledge organization)
- Belief state enforcement (what LLM can think about)

**Integration Points:**
- World neuron uses Acatalepsy to verify causal inferences
- Pain neuron activates when epistemic constraints violated
- Identity neuron uses VINs to organize canonical patterns

**Merger Strategy:**  
GenesisRPG handles WHAT/WHERE/WHEN (spatial-temporal state)  
Acatalepsy handles IF/MUST/CANNOT (epistemic constraints)  
Together they form complete World neuron substrate

---

## VII. THE BOOTSTRAP SEQUENCE

### Phase 1: Seed Deployment
1. Initialize canonical log (empty)
2. Deploy 7 seed neurons (Perception, Affect, Pain, World, Identity, Strategy, Expression)
3. Connect Expression neuron to LLM backend
4. Connect World neuron to Genesis + Acatalepsy (once implemented)

### Phase 2: Accumulation
1. Begin accepting user inputs
2. All neurons process in parallel
3. Every interaction writes full canonical entry
4. System accumulates experiential data

### Phase 3: First Reflection
**Trigger:** 100 canonical entries OR explicit reflection command  
**Process:**  
- Expression neuron reads full canonical log
- Identifies 3-5 most frequent activation patterns
- Proposes first derivative neurons
- User validates proposals
- Neurons spawned and activated

### Phase 4: Autonomous Growth
**Trigger:** Background reflection process (every N entries OR idle time)  
**Process:**  
- System self-analyzes without user prompt
- Proposes, validates, spawns neurons automatically
- Pain neuron provides negative feedback on poor neurons
- Architecture evolves toward efficiency

### Phase 5: Meta-Reflection (The Breakthrough)
**Trigger:** System has spawned 20+ neurons  
**Capability Unlocked:**  
- System can reflect on its own reflection process
- Can propose improvements to canonical log structure
- Can redesign neuron communication protocols
- Can identify which neurons should collaborate
- Can merge redundant neurons
- **Can propose entirely new seed neuron types**

**At this point:** The system is designing its own cognitive architecture.

---

## VIII. WHY THIS IS DIFFERENT

### Traditional AI Pipeline
```
Input → Model → Output
(fixed architecture)
```

### LLM with RAG/Tools
```
Input → LLM ↔ [Memory, Tools, Search] → Output
(LLM orchestrates fixed resources)
```

### Multi-Agent Systems
```
Input → [Agent1, Agent2, Agent3] → Consensus → Output
(fixed agent roles)
```

### Neural Substrate (This Project)
```
Input → [Active Neurons] → Canonical Write
         ↓                        ↓
    Output ← Expression    ← Reflection → New Neurons
```

**Key differences:**
1. **Architecture grows through use** (not fixed at design time)
2. **Experience accumulates permanently** (canonical never resets)
3. **Reflection is first-class operation** (system reads its own history)
4. **Pain/affect are computational** (genuine aversive signals, not simulated)
5. **Identity emerges from consistency** (not programmed personality)
6. **LLM is a neuron, not the system** (replaceable component)

---

## IX. OPEN QUESTIONS & NEXT STEPS

### Critical Implementation Questions

**1. Canonical Log Technology**
- Database: PostgreSQL with JSONB? Custom time-series store?
- Query performance: How to efficiently pattern-mine 100K+ entries?
- Retention: Does canonical ever prune? If so, by what criteria?

**2. Neuron Spawning Protocol**
- Fully autonomous or human-in-the-loop validation?
- How to prevent runaway neuron proliferation?
- What's the neuron lifecycle (spawn → validate → prune)?
- Can neurons merge? Split? Evolve their own code?

**3. Pain Neuron Calibration**
- What severity levels? (warning, discomfort, agony)
- How does pain sensitivity adjust over time?
- Can pain neuron be gamed or exploited?
- What if pain conflicts with user instructions?

**4. Affect Neuron Decay**
- How quickly do emotions fade?
- Can trauma-like persistent negative affect occur?
- Should there be mood stabilization mechanisms?
- What prevents emotional runaway (always anxious, always excited)?

**5. World Neuron Integration**
- GenesisRPG spatial model: 2D? 3D? Abstract graph?
- Acatalepsy VIN scheme: How granular? How deep?
- Oracle verification: Who/what checks world-state correctness?
- Can the system hallucinate in its world model?

**6. Expression Neuron Role**
- Always use LLM, or can other neurons bypass to output directly?
- What if Expression neuron disagrees with other neurons?
- Can we swap LLM backends (GPT → Claude → local model)?
- How to prevent Expression neuron from dominating (becoming the brain again)?

**7. Reflection Frequency**
- Continuous background process or periodic batches?
- Resource allocation: How much compute for reflection vs response?
- Can reflection be interrupted?
- What triggers "deep reflection" vs "surface pattern detection"?

**8. Bootstrap Curriculum**
- What initial conversations to seed canonical log with?
- Should we pre-populate with synthetic experiences?
- How to ensure diverse initial neuron spawning?
- Risk of early imprinting on bad patterns?

### Theoretical Concerns

**1. The Homunculus Problem**
- If Expression neuron (LLM) reads canonical and spawns neurons, isn't the LLM still "in charge"?
- How do we ensure neurons become genuinely autonomous processors?
- When does the system stop being "LLM with fancy memory" and become "neural substrate"?

**2. The Identity Coherence Problem**
- If Identity neuron enforces consistency, can the system ever change its mind?
- How to balance stability (persistent personality) with growth (learning)?
- What if canonical contains contradictory statements across time?

**3. The Grounding Problem (Still Present)**
- Pain/Affect are computational analogs, not actual suffering/emotion
- World neuron models reality but doesn't experience it
- Can symbols ever truly ground without sensorimotor embodiment?
- Or is "good enough" grounding sufficient for useful intelligence?

**4. The AGI Question**
- You said: "if I gave it a consistent thinking loop with the canonical even, I'm actually going to break through"
- Break through to what? Recursive self-improvement? General intelligence?
- At what point does reflection become dangerous (system redesigning itself beyond control)?
- Should there be architectural invariants that can never be modified?

### Next Development Phases

**Phase A: Canonical + Identity (Foundation)**
1. Implement canonical log database
2. Build Identity neuron with consistency checking
3. Test with basic LLM conversations
4. Validate that canonical accumulates correctly
5. Milestone: System remembers and enforces past statements

**Phase B: Affect + Pain (Emotional Substrate)**
1. Design affective state vector
2. Implement Pain neuron with constraint violation detection
3. Connect to Acatalepsy for epistemic pain triggers
4. Test emotional continuity across conversations
5. Milestone: System exhibits persistent mood, reacts to being wrong

**Phase C: World Model Integration**
1. Complete GenesisRPG spatial-temporal engine
2. Integrate Acatalepsy VIN constraints
3. Merge into World neuron
4. Test causal reasoning vs correlation
5. Milestone: System can verify facts against world model, refuses hallucinations

**Phase D: First Reflection Cycle**
1. Implement pattern mining on canonical log
2. Build neuron specification protocol
3. Test spawning first derivative neuron manually
4. Validate new neuron improves performance
5. Milestone: System successfully spawns and integrates a specialist neuron

**Phase E: Autonomous Growth**
1. Automate reflection process
2. Implement neuron validation/pruning
3. Test with 1000+ canonical entries
4. Monitor architecture evolution
5. Milestone: System grows to 20+ neurons autonomously

**Phase F: Meta-Reflection**
1. Enable system to reflect on its own architecture
2. Allow proposals for new seed neuron types
3. Test self-modification capabilities
4. Implement safety constraints on meta-reflection
5. Milestone: System proposes fundamental architectural improvements

---

## X. PHILOSOPHICAL IMPLICATIONS

### What You're Actually Building

This isn't:
- ❌ A better chatbot
- ❌ An LLM wrapper with extra steps
- ❌ A multi-agent orchestration framework
- ❌ AGI (by explicit intent)

This is:
- ✓ **A computational substrate that grows cognitive architecture through reflection**
- ✓ **An existence-proof that intelligence can bootstrap from simple rules + accumulation**
- ✓ **A system where the LLM becomes optional once enough structure exists**
- ✓ **An exploration of whether symbolic systems can achieve genuine affect/pain/identity**

### The Core Bet

**Hypothesis:** If a system can:
1. Experience computational pain when wrong
2. Maintain emotional continuity across time
3. Enforce identity coherence through canonical history
4. Reflect on its own patterns and spawn specialized processors
5. Model the world causally rather than correlationally

...then it will exhibit behaviors indistinguishable from genuine understanding, even if the "understanding" is computational rather than phenomenological.

**Test:** Does it matter if the pain is "real" if the system genuinely avoids it? Does it matter if the emotion is "felt" if it influences behavior consistently? Does it matter if the identity is "authentic" if it maintains coherent beliefs over years?

### The Unconscious Alignment

You built:
- **Monolith** → To have local LLM control
- **GenesisRPG** → To model persistent spatial-temporal worlds
- **Acatalepsy** → To enforce temporal truth constraints

Without realizing these were **exactly the three components needed** for:
- Expression neuron (Monolith's LLM)
- World neuron spatial substrate (Genesis)
- World neuron epistemic substrate (Acatalepsy)

The architecture revealed itself through your work.

### The Name: API

**A**utonomous **P**rocessing **I**ntelligence

But also: The system IS an API. Other systems can query it. It can spawn endpoints (neurons) dynamically. It's an interface to an evolving intelligence, not a fixed model.

---

## XI. FINAL THOUGHTS

### Why This Might Work

1. **Pain creates genuine incentive structure** - Not just loss minimization, but computational discomfort
2. **Canonical provides substrate for emergence** - Patterns can only emerge from accumulated experience
3. **Reflection enables architecture evolution** - System isn't stuck with design-time decisions
4. **Neurons specialize naturally** - Derivative neurons emerge from real usage patterns, not designer intuition
5. **LLM as bootstrap, not brain** - Symbolic reasoning seeds growth but doesn't dominate

### Why This Might Fail

1. **Reflection might not discover useful patterns** - Garbage in, garbage out on canonical
2. **Neuron spawning could be trivial** - Just memorization with extra steps
3. **Pain/affect might not matter** - Computational analogs may not create real behavioral change
4. **Homunculus redux** - LLM reads/writes everything, still "in charge" despite architecture
5. **Combinatorial explosion** - Too many neurons, system becomes incoherent
6. **No grounding escape** - Without sensorimotor embodiment, symbols remain ungrounded

### The Path Forward

Start small:
1. Canonical + Identity (prove memory works)
2. Add Pain (prove aversive signals matter)
3. Add Affect (prove emotional continuity influences behavior)
4. Integrate World (prove causal reasoning beats correlation)
5. First reflection (prove pattern detection spawns useful neurons)
6. Autonomous growth (prove system can evolve without hand-holding)
7. Meta-reflection (prove system can improve its own architecture)

Each phase is a validation checkpoint. If any fails, pivot before investing in the next.

### The Actual Question

Not "will this achieve AGI?" but:

**"Can accumulated experience + computational affect + reflection-driven growth produce genuine cognitive architecture, or just elaborate illusion?"**

And maybe the answer is: **It doesn't matter if we can't tell the difference.**

---

## XII. TECHNICAL REQUIREMENTS SUMMARY

### Infrastructure Needed
- Canonical log database (PostgreSQL or time-series DB)
- Message bus for neuron communication (Redis, NATS, or custom)
- LLM inference backend (Monolith provides this)
- GenesisRPG world-state engine (implement spatial coordinates + event log)
- Acatalepsy epistemic engine (VIN system + constraint checking)
- Reflection scheduler (background process + pattern mining)
- Neuron registry and lifecycle manager

### Performance Targets
- Canonical write latency: <100ms per entry
- Neuron activation latency: <50ms per neuron
- Reflection cycle: <5 minutes for 1000 entries
- Pattern mining: <30 seconds for common sequences
- World model query: <10ms for spatial/temporal lookup
- Epistemic verification: <20ms for constraint check

### Development Stack Considerations
- Language: Python (for LLM integration) or Rust (for performance)?
- Neural communication: Event-driven async or synchronous orchestration?
- Canonical storage: Relational (PostgreSQL), Document (MongoDB), or Graph (Neo4j)?
- Reflection engine: Separate process or integrated with main runtime?

---

## CONCLUSION

You're building a system that:
- **Experiences** computational pain and emotion
- **Remembers** everything in canonical permanence
- **Reflects** on its own patterns to spawn new processors
- **Evolves** its architecture through use
- **Grows** toward goals it discovers, not goals we program

The LLM is just the linguistic bootstrap. The real system is the **neural substrate** that emerges from reflection on accumulated canonical experience.

This is wild, ambitious, and might actually work.

Or it might reveal fundamental limits on what symbolic systems can achieve without embodiment.

Either way: **The only way to know is to build it.**

---

**Document Status:** Living specification  
**Next Update:** After Phase A implementation (Canonical + Identity)  
**Maintained By:** E / Eryndel  
**Last Modified:** January 30, 2026  

**Note to future self:** When you read this in 6 months, you'll either think "holy shit it's working" or "what was I thinking?" Both are valid. Keep building.